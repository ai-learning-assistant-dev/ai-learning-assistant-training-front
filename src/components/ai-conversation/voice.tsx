import { useEffect, useRef, useState, useCallback } from 'react';
import { MicIcon, MicOffIcon, XIcon } from 'lucide-react';
import { cn } from '@/lib/utils';
import { Button } from '@/components/ui/button';
import { FastRTCClient, type Subtitle } from '@/lib/rtc-client';

type VoiceUIProps = {
  userId: string;
  sessionId: string;
  sectionId: string;
  personaId?: string;
  serverUrl: string;
  onClose: () => void;
};

type SubtitleItem = {
  id: string;
  type: 'user' | 'assistant';
  text: string;
  timestamp: number;
};

export const VoiceUI = ({ userId, sessionId, sectionId, personaId, serverUrl, onClose }: VoiceUIProps) => {
  const [isConnected, setIsConnected] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [connectionState, setConnectionState] = useState<string>('disconnected');
  const [subtitles, setSubtitles] = useState<SubtitleItem[]>([]);
  const [currentSubtitle, setCurrentSubtitle] = useState<string>('');

  const rtcClientRef = useRef<FastRTCClient | null>(null);

  // åˆå§‹åŒ– WebRTC è¿æ¥
  useEffect(() => {
    // é˜²æ­¢é‡å¤åˆå§‹åŒ–ï¼šå¦‚æœå·²ç»æœ‰å®ä¾‹ï¼Œç›´æ¥è¿”å›
    if (rtcClientRef.current) {
      console.log('âœ… FastRTCClient å®ä¾‹å·²å­˜åœ¨ï¼Œè·³è¿‡åˆå§‹åŒ–');
      return;
    }

    const initRTC = async () => {
      try {
        // ç¡®ä¿ DOM å…ƒç´ å·²ç»æ¸²æŸ“
        const inputContainer = document.getElementById('input-visualizer');
        const outputContainer = document.getElementById('output-visualizer');

        if (!inputContainer) {
          throw new Error('Input visualizer container not found. DOM may not be ready.');
        }
        if (!outputContainer) {
          throw new Error('Output visualizer container not found. DOM may not be ready.');
        }

        console.log('ğŸš€ å¼€å§‹åˆ›å»º FastRTCClient å®ä¾‹');
        const client = new FastRTCClient({
          serverUrl,
          llmMetadata: {
            userId,
            sessionId,
            sectionId,
            personaId,
            daily: !sectionId,
          },
          visualizer: {
            inputContainerId: 'input-visualizer',
            outputContainerId: 'output-visualizer',
          },
        });

        // å…ˆä¿å­˜å®ä¾‹å¼•ç”¨ï¼Œé˜²æ­¢é‡å¤åˆ›å»º
        rtcClientRef.current = client;
        console.log('âœ… FastRTCClient å®ä¾‹å·²åˆ›å»ºå¹¶ä¿å­˜åˆ° ref');

        client.on('log', (message: string) => {
          console.log('FastRTCClient Log:', message);
        });

        // ç›‘å¬è¿æ¥çŠ¶æ€
        client.on('connect', () => {
          setIsConnected(true);
          setConnectionState('connected');
        });

        client.on('disconnect', () => {
          setIsConnected(false);
          setConnectionState('disconnected');
        });

        client.on('connectionStateChange', state => {
          setConnectionState(state);
        });

        // ç›‘å¬å­—å¹•
        client.on('subtitle', (subtitle: Subtitle) => {
          const newSubtitle: SubtitleItem = {
            id: `${Date.now()}-${Math.random()}`,
            type: subtitle.type === 'request' ? 'user' : 'assistant',
            text: subtitle.text,
            timestamp: Date.now(),
          };

          if (subtitle.type === 'request') {
            // ç”¨æˆ·è¯­éŸ³è¯†åˆ«å­—å¹• - å®æ—¶æ›´æ–°
            setCurrentSubtitle(subtitle.text);
            setSubtitles(prev => [...prev, newSubtitle]);
          } else {
            // AI å“åº”å­—å¹•
            setCurrentSubtitle(subtitle.text);
            setSubtitles(prev => [...prev, newSubtitle]);
          }
        });

        // ç›‘å¬é”™è¯¯
        client.on('error', error => {
          console.error('RTC Error:', error);
          setConnectionState('failed');
        });

        // è¿æ¥åˆ°æœåŠ¡å™¨
        setConnectionState('connecting');
        await client.connect();
        console.log('âœ… FastRTCClient å·²è¿æ¥åˆ°æœåŠ¡å™¨');
      } catch (error) {
        setConnectionState('failed');
        console.error('âŒ Failed to initialize RTC:', error);
        // å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œæ¸…é™¤ ref
        rtcClientRef.current = null;
      }
    };

    initRTC();

    // æ¸…ç†å‡½æ•° - åªåœ¨ç»„ä»¶å¸è½½æ—¶æ‰§è¡Œ
    return () => {
      console.log('ğŸ”´ VoiceUI ç»„ä»¶å¸è½½ï¼Œæ¸…ç† FastRTCClient');
    };
  }, []); // ç©ºä¾èµ–æ•°ç»„ï¼Œåªåœ¨ç»„ä»¶æŒ‚è½½æ—¶æ‰§è¡Œä¸€æ¬¡

  // å¤„ç†éº¦å…‹é£é™éŸ³
  const toggleMute = useCallback(() => {
    if (rtcClientRef.current) {
      const newMutedState = rtcClientRef.current.toggleMute();
      setIsMuted(newMutedState);
    }
  }, []);

  // è·å–çŠ¶æ€é¢œè‰²å’Œæ–‡æœ¬
  const getStateInfo = () => {
    switch (connectionState) {
      case 'connected':
        return { text: 'å·²è¿æ¥ - å¯ä»¥è¯´è¯' };
      case 'connecting':
        return { text: 'æ­£åœ¨è¿æ¥...' };
      case 'disconnected':
        return { text: 'æœªè¿æ¥' };
      case 'failed':
        return { text: 'å‘ç”Ÿé”™è¯¯ï¼Œè¯·é€€å‡ºé‡è¯•ã€‚' };
      default:
        return { text: connectionState };
    }
  };

  // ç›‘å¬è¿æ¥çŠ¶æ€å˜åŒ–
  useEffect(() => {
    // console.log("connectionState", connectionState);
    const info = getStateInfo();
    setCurrentSubtitle(info.text);
    setSubtitles(prev => {
      if (prev.length > 0 && prev[prev.length - 1].text === info.text) return prev;

      const newSubtitle: SubtitleItem = {
        id: `${Date.now()}-${Math.random()}`,
        type: 'assistant',
        text: info.text,
        timestamp: Date.now(),
      };

      return [...prev, newSubtitle];
    });
  }, [connectionState]);

  const closeVoice = useCallback(async () => {
    if (rtcClientRef.current) {
      await rtcClientRef.current.disconnect();
      rtcClientRef.current = null;
    }
    onClose();
  }, [onClose]);

  return (
    <div className='flex-1 flex flex-col pl-8 pr-8 relative'>
      {/* Main Voice Interface */}
      <div className='flex-1 flex flex-col items-center justify-between gap-1'>
        {/* AI è¯­éŸ³è¾“å‡ºå¯è§†åŒ–åœ†çƒ (èƒŒæ™¯é€æ˜) */}
        <div className='relative'>
          <div className={cn('w-40 h-40 flex items-center justify-center')}>
            <div id='output-visualizer' className='w-full h-full' />
          </div>
        </div>

        {/* ç”¨æˆ·è¯­éŸ³è¾“å…¥æ³¢å½¢ (èƒŒæ™¯é€æ˜) */}
        <div className='w-full max-w-md'>
          <div id='input-visualizer' className='h-32 w-full' />
        </div>

        {/* å­—å¹•æ˜¾ç¤ºåŒºåŸŸ */}
        <div className='w-full max-w-2xl'>
          <div className='bg-white rounded-lg border border-gray-200 shadow-sm p-4 min-h-[200px] max-h-[400px] overflow-y-auto'>
            <div className='text-xs text-gray-400 mb-2'>å®æ—¶å­—å¹•</div>

            {/* ä¸Šä¸€å¥å­—å¹• - è¾ƒå°ã€è¾ƒæ·¡ */}
            {subtitles.length > 0 && <div className='text-sm text-gray-400 mb-4 pb-4 border-b border-gray-100'>{subtitles[subtitles.length - 2]?.text?.trim() || ''}</div>}

            {/* å½“å‰å­—å¹• - è¾ƒå¤§ã€è¾ƒæ·± */}
            <div className='text-base text-gray-900 whitespace-pre-wrap'>{currentSubtitle?.trim() || 'ç­‰å¾…è¯­éŸ³è¾“å…¥...'}</div>
          </div>
        </div>

        {/* æ§åˆ¶æŒ‰é’® - Fixed at bottom */}
        <div className='flex gap-3 justify-center pb-4'>
          <Button variant='outline' size='icon' onClick={toggleMute} disabled={!isConnected} className={cn('w-12 h-12 rounded-full', isMuted && 'bg-red-100 hover:bg-red-200')}>
            {isMuted ? <MicOffIcon className='h-5 w-5 text-red-600' /> : <MicIcon className='h-5 w-5' />}
          </Button>

          <Button variant='destructive' size='icon' onClick={closeVoice} className='w-12 h-12 rounded-full' disabled={!['failed', 'connected'].includes(connectionState)}>
            <XIcon className='h-5 w-5' />
          </Button>
        </div>
      </div>
    </div>
  );
};
